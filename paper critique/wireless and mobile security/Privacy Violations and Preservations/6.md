## Fawkes: Protecting Privacy against Unauthorized Deep Learning Models

**Paper Summary**

How do we protect ourselves against unauthorized third parties building facial recognition models that recognize us? The authors have developed Fawkes, an algorithm and software tool that gives individuals the ability to limit how unknown third parties can track them by building facial recognition models out of their publicly available photos. By putting hidden changes into your photos, Fawkes could trick models that try to learn what you look like while you could still use your "cloaked" images normally in daily life.

**Strengths**

- The Fawkes takes personal images and makes tiny, pixel-level changes that are invisible to the human eyes, called "image cloaking". People could still use the cloaked images as normal like sharing and printing.

- The cloak effect is not easily detectable by humans or machines and will not cause errors in model training. Models could still use these photos to build a facial recognition model, but "cloaked" images will teach the model a highly distorted version of facial features so that the model cannot learn and identify you in images.

- Fawke s has been tested extensively and proven effective in a variety of environments and is 100% effective against state-of-the-art facial recognition models of many big company like Facebook++, Microsoft and so on.


**Weaknesses**

- The protection level of Fawkes will vary according to users' willingness to tolerate tweaks to their images.

- Noise and distortion may be added at a high enough level to distort and break the cloak of the image.

- Fawkes uses adversarial examples, which is the fundamental weaknesses of today's DNNs design -- small tweaks in inputs that can produce massive differences in how DNNs classify the input. It is possible that DNNs evolve significantly to eliminate this property, and the Fawkes will then be useless.


**Improvements**

As the users of Fawkes reported, though Fawkes could against DNN facial recognition model, the cloaking effect on the original images are sometimes cannot be accept by users for daily use. Authors should try to improve the algorithm to balance the protection level of Fawkes and the tweaks to the images.